# Task Breakdown: SEO Checker MVP

**Spec ID**: 001-seo-checker  
**Phase**: Tasks  
**Created**: 2026-02-18  
**Status**: Ready for Implementation

> **Navigation**: See [PLAN.md](./PLAN.md) for module details and [README.md](./README.md) for full documentation.

---

## Overview

This document breaks down the implementation plan into **42 concrete tasks** following TDD methodology.

**Total Estimated Time**: 25-32 hours

**Task Types**:
- `[CONFIG]` ‚Äî Configuration, setup, infrastructure
- `[TEST]` ‚Äî Write tests (RED phase)
- `[IMPL]` ‚Äî Implementation (GREEN phase)
- `[REFACTOR]` ‚Äî Code improvement, optimization

**Status Legend**:
- ‚è≥ Not Started
- üîÑ In Progress
- ‚úÖ Completed
- ‚è≠Ô∏è Blocked (waiting for dependencies)

---

## Module 1: Project Setup (2-3 hours)

### TASK-001: Initialize Project Structure
**Type**: `[CONFIG]`  
**Time**: 30 min  
**Status**: ‚è≥

**Description**: Create directory structure and base files.

**Files to Create**:
```
seo-checker-tool/
‚îú‚îÄ‚îÄ backend/
‚îÇ   ‚îú‚îÄ‚îÄ app/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ main.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ models.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ database.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ routes/
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ checks/
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ utils/
‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ tests/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ conftest.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ unit/
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ integration/
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ e2e/
‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ requirements.txt
‚îÇ   ‚îú‚îÄ‚îÄ .env.example
‚îÇ   ‚îî‚îÄ‚îÄ README.md
‚îÇ
‚îî‚îÄ‚îÄ telegram-bot/
    ‚îú‚îÄ‚îÄ bot.py
    ‚îú‚îÄ‚îÄ handlers/
    ‚îÇ   ‚îî‚îÄ‚îÄ __init__.py
    ‚îú‚îÄ‚îÄ services/
    ‚îÇ   ‚îî‚îÄ‚îÄ __init__.py
    ‚îú‚îÄ‚îÄ tests/
    ‚îÇ   ‚îî‚îÄ‚îÄ __init__.py
    ‚îú‚îÄ‚îÄ requirements.txt
    ‚îú‚îÄ‚îÄ .env.example
    ‚îî‚îÄ‚îÄ README.md
```

**Commands**:
```bash
cd /Users/aleksejsermazko/Documents/Cursor/work/git/blog/SEO/seo-checker-tool
mkdir -p backend/app/{routes,checks,utils}
mkdir -p backend/tests/{unit/checks,integration,e2e}
mkdir -p telegram-bot/{handlers,services,tests}
touch backend/app/__init__.py backend/app/main.py
# ... create all files
```

**Acceptance Criteria**:
- ‚úÖ All directories created
- ‚úÖ All `__init__.py` files present
- ‚úÖ Base `main.py` with "Hello World" FastAPI app
- ‚úÖ Can import modules without errors

**Dependencies**: None

---

### TASK-002: Setup Dependencies
**Type**: `[CONFIG]`  
**Time**: 30 min  
**Status**: ‚è≥

**Description**: Create requirements.txt and install dependencies.

**Files to Create/Modify**:
- `backend/requirements.txt`
- `telegram-bot/requirements.txt`

**Backend Dependencies**:
```txt
# backend/requirements.txt
fastapi==0.109.0
uvicorn[standard]==0.27.0
sqlalchemy==2.0.25
psycopg2-binary==2.9.9
pydantic==2.5.3
pydantic-settings==2.1.0
httpx==0.26.0
beautifulsoup4==4.12.3
lxml==5.1.0

# Development
pytest==7.4.4
pytest-asyncio==0.23.3
pytest-cov==4.1.0
ruff==0.1.14
mypy==1.8.0
```

**Bot Dependencies**:
```txt
# telegram-bot/requirements.txt
python-telegram-bot==20.7
httpx==0.26.0
pydantic==2.5.3
pydantic-settings==2.1.0

# Development
pytest==7.4.4
pytest-asyncio==0.23.3
```

**Commands**:
```bash
cd backend/
python -m venv .venv
source .venv/bin/activate
pip install -r requirements.txt

cd ../telegram-bot/
python -m venv .venv
source .venv/bin/activate
pip install -r requirements.txt
```

**Acceptance Criteria**:
- ‚úÖ Both virtual environments created
- ‚úÖ All dependencies installed
- ‚úÖ `pip list` shows correct versions
- ‚úÖ No import errors

**Dependencies**: TASK-001

---

### TASK-003: Configure Linters
**Type**: `[CONFIG]`  
**Time**: 30 min  
**Status**: ‚è≥

**Description**: Setup ruff and mypy for code quality.

**Files to Create**:
- `backend/pyproject.toml`
- `backend/.ruff.toml`
- `backend/mypy.ini`

**backend/pyproject.toml**:
```toml
[tool.ruff]
line-length = 100
target-version = "py311"
select = ["E", "F", "I", "N", "W", "UP"]

[tool.pytest.ini_options]
testpaths = ["tests"]
python_files = "test_*.py"
python_functions = "test_*"
asyncio_mode = "auto"
```

**backend/mypy.ini**:
```ini
[mypy]
python_version = 3.11
warn_return_any = True
warn_unused_configs = True
disallow_untyped_defs = True
```

**Commands**:
```bash
cd backend/
ruff check app/
mypy app/
```

**Acceptance Criteria**:
- ‚úÖ Ruff configured and runs without errors
- ‚úÖ Mypy configured
- ‚úÖ Can run linters on codebase
- ‚úÖ Pre-commit hook optional (can add later)

**Dependencies**: TASK-002

---

### TASK-004: Setup Database Schema
**Type**: `[CONFIG]`  
**Time**: 1 hour  
**Status**: ‚è≥

**Description**: Create database models and initial migration.

**Files to Create**:
- `backend/app/database.py` ‚Äî DB connection
- `backend/app/models.py` ‚Äî SQLAlchemy models
- `backend/migrations/001_initial_schema.sql` ‚Äî SQL migration

**Reference**: [database/schema.md](./database/schema.md)

**backend/app/database.py**:
```python
from sqlalchemy.ext.asyncio import AsyncSession, create_async_engine
from sqlalchemy.orm import sessionmaker, declarative_base
from pydantic_settings import BaseSettings

class Settings(BaseSettings):
    database_url: str = "postgresql+asyncpg://localhost/seo_checker"
    
    class Config:
        env_file = ".env"

settings = Settings()
engine = create_async_engine(settings.database_url, echo=True)
AsyncSessionLocal = sessionmaker(engine, class_=AsyncSession, expire_on_commit=False)
Base = declarative_base()

async def get_db() -> AsyncSession:
    async with AsyncSessionLocal() as session:
        yield session
```

**backend/app/models.py**:
```python
from sqlalchemy import Column, Integer, String, BigInteger, DECIMAL, ForeignKey, TIMESTAMP, func
from sqlalchemy.dialects.postgresql import JSONB
from sqlalchemy.orm import relationship
from .database import Base

class CheckRequest(Base):
    __tablename__ = "check_requests"
    
    id = Column(Integer, primary_key=True, index=True)
    telegram_id = Column(BigInteger, nullable=False, index=True)
    username = Column(String(255), nullable=True)
    site_url = Column(String(500), nullable=False)
    status = Column(String(50), default="pending")
    created_at = Column(TIMESTAMP, default=func.now())
    updated_at = Column(TIMESTAMP, default=func.now(), onupdate=func.now())
    
    result = relationship("CheckResult", back_populates="request", uselist=False)

class CheckResult(Base):
    __tablename__ = "check_results"
    
    id = Column(Integer, primary_key=True, index=True)
    check_request_id = Column(Integer, ForeignKey("check_requests.id", ondelete="CASCADE"))
    score = Column(DECIMAL(3, 1), nullable=False)
    problems_critical = Column(Integer, default=0)
    problems_important = Column(Integer, default=0)
    checks_ok = Column(Integer, default=0)
    report_data = Column(JSONB, nullable=False)
    detailed_checks = Column(JSONB, nullable=False)
    processing_time_sec = Column(Integer, nullable=True)
    created_at = Column(TIMESTAMP, default=func.now())
    
    request = relationship("CheckRequest", back_populates="result")
```

**Commands**:
```bash
# Local PostgreSQL (Docker)
docker run -d -p 5432:5432 \
  -e POSTGRES_USER=seo_checker \
  -e POSTGRES_PASSWORD=dev \
  -e POSTGRES_DB=seo_checker \
  postgres:14

# Run migration
psql postgresql://seo_checker:dev@localhost/seo_checker \
  -f backend/migrations/001_initial_schema.sql
```

**Acceptance Criteria**:
- ‚úÖ Database connection works
- ‚úÖ Models defined (CheckRequest, CheckResult)
- ‚úÖ Migration creates tables
- ‚úÖ Can query database with SQLAlchemy

**Dependencies**: TASK-002

---

## Module 2: Core Checks (8-10 hours)

### TASK-005: [TEST] Robots.txt Check
**Type**: `[TEST]`  
**Time**: 30 min  
**Status**: ‚è≥

**Description**: Write unit tests for robots.txt check.

**Files to Create**:
- `backend/tests/unit/checks/test_robots_txt.py`
- `backend/tests/conftest.py` ‚Äî Shared fixtures

**Test Cases**:
1. Valid robots.txt with User-agent and Sitemap ‚Üí `status="ok"`
2. Valid robots.txt without Sitemap ‚Üí `status="partial"`
3. 404 Not Found ‚Üí `status="problem"`
4. Empty file ‚Üí `status="problem"`
5. Timeout ‚Üí `status="error"`

**Example Test**:
```python
import pytest
from app.checks.robots_txt import check_robots_txt
from app.checks.base import CheckResult

@pytest.mark.asyncio
async def test_robots_txt_valid(mock_http_client):
    # Arrange
    mock_http_client.get.return_value = MockResponse(
        status_code=200,
        text="User-agent: *\nSitemap: https://example.ru/sitemap.xml"
    )
    
    # Act
    result = await check_robots_txt("https://example.ru", mock_http_client)
    
    # Assert
    assert result.status == "ok"
    assert "User-agent –∏ Sitemap" in result.message
    assert result.severity is None
```

**Reference**: [checks/mvp-checks.md#check-1-robotstxt](./checks/mvp-checks.md#check-1-robotstxt)

**Acceptance Criteria**:
- ‚úÖ 5 test cases written
- ‚úÖ Tests fail (RED) because implementation doesn't exist yet
- ‚úÖ Tests use mocked HTTP client
- ‚úÖ Clear, descriptive test names

**Dependencies**: TASK-004

---

### TASK-006: [IMPL] Robots.txt Check
**Type**: `[IMPL]`  
**Time**: 1 hour  
**Status**: ‚è≥

**Description**: Implement robots.txt check to pass tests.

**Files to Create**:
- `backend/app/checks/base.py` ‚Äî CheckResult dataclass
- `backend/app/checks/robots_txt.py` ‚Äî Implementation

**backend/app/checks/base.py**:
```python
from dataclasses import dataclass
from typing import Literal, Optional

@dataclass
class CheckResult:
    id: str
    name: str
    status: Literal["ok", "partial", "problem", "error"]
    message: str
    severity: Optional[Literal["critical", "important", "enhancement"]] = None
    category: str = "technical"
```

**backend/app/checks/robots_txt.py**:
```python
import httpx
from .base import CheckResult

async def check_robots_txt(site_url: str, client: httpx.AsyncClient) -> CheckResult:
    """Check robots.txt presence and content."""
    url = f"{site_url}/robots.txt"
    
    try:
        response = await client.get(url, timeout=5.0)
        
        if response.status_code != 200:
            return CheckResult(
                id="tech-robots",
                name="Robots.txt",
                status="problem",
                message="‚ùå –§–∞–π–ª robots.txt –Ω–µ –Ω–∞–π–¥–µ–Ω",
                severity="critical"
            )
        
        content = response.text.lower()
        has_user_agent = "user-agent:" in content
        has_sitemap = "sitemap:" in content
        
        if has_user_agent and has_sitemap:
            return CheckResult(
                id="tech-robots",
                name="Robots.txt",
                status="ok",
                message="‚úÖ –§–∞–π–ª –Ω–∞–π–¥–µ–Ω, —Å–æ–¥–µ—Ä–∂–∏—Ç User-agent –∏ Sitemap"
            )
        elif has_user_agent:
            return CheckResult(
                id="tech-robots",
                name="Robots.txt",
                status="partial",
                message="‚ö†Ô∏è –§–∞–π–ª –Ω–∞–π–¥–µ–Ω, –Ω–æ –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç Sitemap",
                severity="important"
            )
        else:
            return CheckResult(
                id="tech-robots",
                name="Robots.txt",
                status="problem",
                message="‚ùå –§–∞–π–ª –Ω–∞–π–¥–µ–Ω, –Ω–æ –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç User-agent",
                severity="critical"
            )
    
    except httpx.TimeoutException:
        return CheckResult(
            id="tech-robots",
            name="Robots.txt",
            status="error",
            message="‚ö†Ô∏è Timeout –ø—Ä–∏ –ø—Ä–æ–≤–µ—Ä–∫–µ robots.txt"
        )
    except Exception as e:
        return CheckResult(
            id="tech-robots",
            name="Robots.txt",
            status="error",
            message=f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏: {str(e)}"
        )
```

**Commands**:
```bash
cd backend/
pytest tests/unit/checks/test_robots_txt.py -v
```

**Acceptance Criteria**:
- ‚úÖ All 5 tests pass (GREEN)
- ‚úÖ Type hints on all functions
- ‚úÖ Docstring present
- ‚úÖ Handles all edge cases

**Dependencies**: TASK-005

---

### TASK-007: [TEST] Sitemap.xml Check
**Type**: `[TEST]`  
**Time**: 30 min  
**Status**: ‚è≥

**Description**: Write unit tests for sitemap.xml check.

**Files to Create**:
- `backend/tests/unit/checks/test_sitemap_xml.py`

**Test Cases**:
1. Valid sitemap with URLs ‚Üí `status="ok"`
2. Sitemap index ‚Üí `status="partial"`
3. 404 Not Found ‚Üí `status="problem"`
4. Invalid XML ‚Üí `status="problem"`
5. Empty sitemap ‚Üí `status="problem"`

**Reference**: [checks/mvp-checks.md#check-2-sitemapxml](./checks/mvp-checks.md#check-2-sitemapxml)

**Acceptance Criteria**:
- ‚úÖ 5 test cases written
- ‚úÖ Tests fail (RED)
- ‚úÖ Mocked XML responses

**Dependencies**: TASK-006

---

### TASK-008: [IMPL] Sitemap.xml Check
**Type**: `[IMPL]`  
**Time**: 1 hour  
**Status**: ‚è≥

**Description**: Implement sitemap.xml check.

**Files to Create**:
- `backend/app/checks/sitemap_xml.py`

**Implementation**: XML parsing with `xml.etree.ElementTree`

**Acceptance Criteria**:
- ‚úÖ All tests pass (GREEN)
- ‚úÖ Handles namespaces correctly
- ‚úÖ Distinguishes between sitemap and sitemap index

**Dependencies**: TASK-007

---

### TASK-009: [TEST] Analytics Check
**Type**: `[TEST]`  
**Time**: 20 min  
**Status**: ‚è≥

**Description**: Write unit tests for analytics counters check.

**Files to Create**:
- `backend/tests/unit/checks/test_analytics.py`

**Test Cases**:
1. Yandex.Metrika found ‚Üí `status="ok"`
2. Google Analytics found ‚Üí `status="ok"`
3. Both found ‚Üí `status="ok"`
4. None found ‚Üí `status="problem"`

**Reference**: [checks/mvp-checks.md#check-6-analytics-counters](./checks/mvp-checks.md#check-6-analytics-counters)

**Acceptance Criteria**:
- ‚úÖ 4 test cases written
- ‚úÖ Tests fail (RED)

**Dependencies**: TASK-008

---

### TASK-010: [IMPL] Analytics Check
**Type**: `[IMPL]`  
**Time**: 45 min  
**Status**: ‚è≥

**Description**: Implement analytics check.

**Files to Create**:
- `backend/app/checks/analytics.py`

**Implementation**: Search HTML for:
- `mc.yandex.ru/metrika`
- `googletagmanager.com/gtag`
- `google-analytics.com/analytics.js`

**Acceptance Criteria**:
- ‚úÖ All tests pass (GREEN)
- ‚úÖ Detects both Yandex and Google

**Dependencies**: TASK-009

---

### TASK-011: [TEST] Noindex Check
**Type**: `[TEST]`  
**Time**: 30 min  
**Status**: ‚è≥

**Description**: Write unit tests for noindex check.

**Files to Create**:
- `backend/tests/unit/checks/test_noindex.py`

**Test Cases**:
1. No noindex meta tag ‚Üí `status="ok"`
2. Noindex found ‚Üí `status="problem"` (critical)
3. X-Robots-Tag header with noindex ‚Üí `status="problem"`
4. Page unreachable ‚Üí `status="error"`

**Reference**: [checks/mvp-checks.md#check-3-noindex-on-main-page](./checks/mvp-checks.md#check-3-noindex-on-main-page)

**Acceptance Criteria**:
- ‚úÖ 4 test cases written
- ‚úÖ Tests fail (RED)

**Dependencies**: TASK-010

---

### TASK-012: [IMPL] Noindex Check
**Type**: `[IMPL]`  
**Time**: 1 hour  
**Status**: ‚è≥

**Description**: Implement noindex check.

**Files to Create**:
- `backend/app/checks/noindex.py`

**Implementation**:
- Parse HTML with BeautifulSoup
- Check `<meta name="robots" content="noindex">`
- Check HTTP headers `X-Robots-Tag`

**Acceptance Criteria**:
- ‚úÖ All tests pass (GREEN)
- ‚úÖ Checks both meta tag and HTTP header

**Dependencies**: TASK-011

---

### TASK-013: [TEST] Meta Tags Check
**Type**: `[TEST]`  
**Time**: 30 min  
**Status**: ‚è≥

**Description**: Write unit tests for meta tags check.

**Files to Create**:
- `backend/tests/unit/checks/test_meta_tags.py`

**Test Cases**:
1. Optimal title & description ‚Üí `status="ok"`
2. Missing title ‚Üí `status="problem"`
3. Short title (< 30 chars) ‚Üí `status="partial"`
4. Long description (> 160 chars) ‚Üí `status="partial"`
5. Both missing ‚Üí `status="problem"`

**Reference**: [checks/mvp-checks.md#check-4-meta-tags](./checks/mvp-checks.md#check-4-meta-tags)

**Acceptance Criteria**:
- ‚úÖ 5 test cases written
- ‚úÖ Tests fail (RED)

**Dependencies**: TASK-012

---

### TASK-014: [IMPL] Meta Tags Check
**Type**: `[IMPL]`  
**Time**: 1 hour  
**Status**: ‚è≥

**Description**: Implement meta tags check.

**Files to Create**:
- `backend/app/checks/meta_tags.py`

**Implementation**:
- Extract `<title>` and `<meta name="description">`
- Check lengths (title: 30-65, description: 120-160)
- Return appropriate status

**Acceptance Criteria**:
- ‚úÖ All tests pass (GREEN)
- ‚úÖ Correct length validation

**Dependencies**: TASK-013

---

### TASK-015: [TEST] Headings Check
**Type**: `[TEST]`  
**Time**: 20 min  
**Status**: ‚è≥

**Description**: Write unit tests for headings check.

**Files to Create**:
- `backend/tests/unit/checks/test_headings.py`

**Test Cases**:
1. 1 H1 + H2s ‚Üí `status="ok"`
2. No H1 ‚Üí `status="problem"`
3. Multiple H1s ‚Üí `status="partial"`
4. H1 but no H2 ‚Üí `status="partial"`

**Reference**: [checks/mvp-checks.md#check-5-h1h2-structure](./checks/mvp-checks.md#check-5-h1h2-structure)

**Acceptance Criteria**:
- ‚úÖ 4 test cases written
- ‚úÖ Tests fail (RED)

**Dependencies**: TASK-014

---

### TASK-016: [IMPL] Headings Check
**Type**: `[IMPL]`  
**Time**: 45 min  
**Status**: ‚è≥

**Description**: Implement headings check.

**Files to Create**:
- `backend/app/checks/headings.py`

**Implementation**:
- Find all `<h1>` and `<h2>` tags
- Count them
- Return status based on counts

**Acceptance Criteria**:
- ‚úÖ All tests pass (GREEN)
- ‚úÖ Correct H1/H2 validation

**Dependencies**: TASK-015

---

## Module 3: Report Builder (2 hours)

### TASK-017: [TEST] Score Calculator
**Type**: `[TEST]`  
**Time**: 20 min  
**Status**: ‚è≥

**Description**: Write tests for score calculation.

**Files to Create**:
- `backend/tests/unit/test_report_builder.py`

**Test Cases**:
1. All checks ok (6/6) ‚Üí score = 10.0
2. 5 ok + 1 partial ‚Üí score = 9.2
3. 4 ok + 2 problem ‚Üí score = 6.7
4. All problem ‚Üí score = 0.0

**Formula**: `(ok * 1.0 + partial * 0.5) / total * 10`

**Acceptance Criteria**:
- ‚úÖ 4 test cases written
- ‚úÖ Tests fail (RED)

**Dependencies**: TASK-016

---

### TASK-018: [IMPL] Report Builder
**Type**: `[IMPL]`  
**Time**: 1.5 hours  
**Status**: ‚è≥

**Description**: Implement report builder logic.

**Files to Create**:
- `backend/app/report_builder.py`

**Functions**:
1. `calculate_score(checks: list[CheckResult]) -> float`
2. `group_by_category(checks: list[CheckResult]) -> list[dict]`
3. `extract_top_priorities(checks: list[CheckResult]) -> list[dict]`
4. `build_report(checks: list[CheckResult]) -> dict`

**Reference**: [api/contracts.md](./api/contracts.md)

**Acceptance Criteria**:
- ‚úÖ All tests pass (GREEN)
- ‚úÖ Correct score calculation
- ‚úÖ Categories grouped
- ‚úÖ Top 3 priorities extracted

**Dependencies**: TASK-017

---

## Module 4: Backend API (4-5 hours)

### TASK-019: [TEST] API Endpoint - Happy Path
**Type**: `[TEST]`  
**Time**: 30 min  
**Status**: ‚è≥

**Description**: Write integration test for successful check.

**Files to Create**:
- `backend/tests/integration/test_api_check_endpoint.py`

**Test Case**: POST /api/check with valid URL ‚Üí 200 OK + full report

**Acceptance Criteria**:
- ‚úÖ Test written
- ‚úÖ Test fails (RED)
- ‚úÖ Uses test database

**Dependencies**: TASK-018

---

### TASK-020: [IMPL] API Endpoint
**Type**: `[IMPL]`  
**Time**: 2 hours  
**Status**: ‚è≥

**Description**: Implement POST /api/check endpoint.

**Files to Create/Modify**:
- `backend/app/routes/check.py`
- `backend/app/main.py` ‚Äî Add route

**Flow**:
1. Validate request (site_url, telegram_id)
2. Check rate limit
3. Save CheckRequest to DB
4. Run all 6 checks in parallel (`asyncio.gather`)
5. Build report
6. Save CheckResult to DB
7. Return JSON

**Reference**: [api/contracts.md](./api/contracts.md)

**Acceptance Criteria**:
- ‚úÖ Test passes (GREEN)
- ‚úÖ All 6 checks run
- ‚úÖ Database saves records
- ‚úÖ Returns correct JSON structure

**Dependencies**: TASK-019

---

### TASK-021: [TEST] API - Rate Limiting
**Type**: `[TEST]`  
**Time**: 20 min  
**Status**: ‚è≥

**Description**: Write test for rate limit (5/hour).

**Test Case**: 6 requests in quick succession ‚Üí 6th returns 429

**Acceptance Criteria**:
- ‚úÖ Test written
- ‚úÖ Test fails (RED)

**Dependencies**: TASK-020

---

### TASK-022: [IMPL] Rate Limiting
**Type**: `[IMPL]`  
**Time**: 1 hour  
**Status**: ‚è≥

**Description**: Implement rate limiting logic.

**Implementation**:
- Query: `SELECT COUNT(*) WHERE telegram_id = ? AND created_at > NOW() - INTERVAL '1 hour'`
- If >= 5, return 429

**Acceptance Criteria**:
- ‚úÖ Test passes (GREEN)
- ‚úÖ Returns 429 with retry_after_sec

**Dependencies**: TASK-021

---

### TASK-023: [TEST] API - Error Handling
**Type**: `[TEST]`  
**Time**: 30 min  
**Status**: ‚è≥

**Description**: Write tests for error cases.

**Test Cases**:
1. Invalid URL ‚Üí 400
2. Site unreachable ‚Üí 200 (partial report)
3. Timeout ‚Üí 504

**Acceptance Criteria**:
- ‚úÖ 3 tests written
- ‚úÖ Tests fail (RED)

**Dependencies**: TASK-022

---

### TASK-024: [IMPL] Error Handling
**Type**: `[IMPL]`  
**Time**: 1 hour  
**Status**: ‚è≥

**Description**: Implement error handling.

**Implementation**:
- URL validation
- Graceful degradation (continue if 1 check fails)
- Timeout handling (120 sec total)

**Acceptance Criteria**:
- ‚úÖ All error tests pass (GREEN)
- ‚úÖ Proper error responses

**Dependencies**: TASK-023

---

### TASK-025: [IMPL] Health Endpoint
**Type**: `[IMPL]`  
**Time**: 15 min  
**Status**: ‚è≥

**Description**: Add GET /api/health endpoint.

**Response**:
```json
{
  "status": "ok",
  "version": "1.0.0",
  "checks": {
    "database": "ok"
  }
}
```

**Acceptance Criteria**:
- ‚úÖ Endpoint returns 200
- ‚úÖ Can check DB connection

**Dependencies**: TASK-024

---

## Module 5: Telegram Bot (4-5 hours)

### TASK-026: [CONFIG] Bot Setup
**Type**: `[CONFIG]`  
**Time**: 30 min  
**Status**: ‚è≥

**Description**: Initialize bot with python-telegram-bot.

**Files to Create**:
- `telegram-bot/bot.py` ‚Äî Main entry point
- `telegram-bot/.env.example`

**bot.py** (basic structure):
```python
import os
from telegram import Update
from telegram.ext import Application, CommandHandler, ContextTypes

BOT_TOKEN = os.getenv("BOT_TOKEN")
API_URL = os.getenv("API_URL", "http://localhost:8000")

async def start(update: Update, context: ContextTypes.DEFAULT_TYPE):
    await update.message.reply_text("Hello!")

def main():
    app = Application.builder().token(BOT_TOKEN).build()
    app.add_handler(CommandHandler("start", start))
    app.run_polling()

if __name__ == "__main__":
    main()
```

**Commands**:
```bash
cd telegram-bot/
export BOT_TOKEN="your_token"
python bot.py
```

**Acceptance Criteria**:
- ‚úÖ Bot starts without errors
- ‚úÖ Responds to /start command
- ‚úÖ Environment variables loaded

**Dependencies**: TASK-002

---

### TASK-027: [TEST] Start Handler with Deep Link
**Type**: `[TEST]`  
**Time**: 30 min  
**Status**: ‚è≥

**Description**: Write tests for /start handler.

**Files to Create**:
- `telegram-bot/tests/test_handlers.py`

**Test Cases**:
1. /start without args ‚Üí welcome message
2. /start check_URL ‚Üí parse URL, call API

**Acceptance Criteria**:
- ‚úÖ 2 tests written
- ‚úÖ Tests fail (RED)

**Dependencies**: TASK-026

---

### TASK-028: [IMPL] Start Handler
**Type**: `[IMPL]`  
**Time**: 1.5 hours  
**Status**: ‚è≥

**Description**: Implement /start handler with deep link parsing.

**Files to Create**:
- `telegram-bot/handlers/start.py`

**Flow**:
1. Parse args: `["check_aHR0cHM6Ly9leGFtcGxlLnJ1"]`
2. Decode Base64 ‚Üí site_url
3. Send "‚è≥ –ü—Ä–æ–≤–µ—Ä—è—é —Å–∞–π—Ç..."
4. Call API
5. Format report
6. Send to user

**Reference**: [telegram/bot-logic.md](./telegram/bot-logic.md)

**Acceptance Criteria**:
- ‚úÖ Tests pass (GREEN)
- ‚úÖ Deep link parsed correctly
- ‚úÖ Sends "checking" message

**Dependencies**: TASK-027

---

### TASK-029: [TEST] API Client
**Type**: `[TEST]`  
**Time**: 20 min  
**Status**: ‚è≥

**Description**: Write tests for API client.

**Files to Create**:
- `telegram-bot/tests/test_api_client.py`

**Test Cases**:
1. Successful response ‚Üí return report
2. 429 rate limit ‚Üí return error
3. Timeout ‚Üí return error

**Acceptance Criteria**:
- ‚úÖ 3 tests written
- ‚úÖ Tests fail (RED)

**Dependencies**: TASK-028

---

### TASK-030: [IMPL] API Client
**Type**: `[IMPL]`  
**Time**: 1 hour  
**Status**: ‚è≥

**Description**: Implement API client for Backend.

**Files to Create**:
- `telegram-bot/services/api_client.py`

**Methods**:
```python
async def check_site(site_url: str, telegram_id: int) -> dict:
    """Call Backend API to check site."""
    ...
```

**Retry Logic**:
- 500 error ‚Üí retry once
- 429, 400 ‚Üí no retry

**Acceptance Criteria**:
- ‚úÖ Tests pass (GREEN)
- ‚úÖ Retry logic works

**Dependencies**: TASK-029

---

### TASK-031: [TEST] Report Formatter
**Type**: `[TEST]`  
**Time**: 30 min  
**Status**: ‚è≥

**Description**: Write tests for report formatting.

**Files to Create**:
- `telegram-bot/tests/test_formatter.py`

**Test Cases**:
1. High score (8+) ‚Üí üü¢ emoji
2. Low score (<5) ‚Üí üî¥ emoji
3. Format includes all sections

**Acceptance Criteria**:
- ‚úÖ 3 tests written
- ‚úÖ Tests fail (RED)

**Dependencies**: TASK-030

---

### TASK-032: [IMPL] Report Formatter
**Type**: `[IMPL]`  
**Time**: 1 hour  
**Status**: ‚è≥

**Description**: Implement report formatting for Telegram.

**Files to Create**:
- `telegram-bot/services/formatter.py`

**Function**:
```python
def format_report(report: dict) -> str:
    """Convert API response to Telegram Markdown."""
    ...
```

**Reference**: [telegram/bot-logic.md#report-formatting](./telegram/bot-logic.md#report-formatting)

**Acceptance Criteria**:
- ‚úÖ Tests pass (GREEN)
- ‚úÖ Correct emoji based on score
- ‚úÖ Personalized CTA

**Dependencies**: TASK-031

---

### TASK-033: [IMPL] Help Handler
**Type**: `[IMPL]`  
**Time**: 15 min  
**Status**: ‚è≥

**Description**: Add /help command.

**Files to Create**:
- `telegram-bot/handlers/help.py`

**Response**: Static help message

**Acceptance Criteria**:
- ‚úÖ /help responds correctly

**Dependencies**: TASK-032

---

## Module 6: Integration & E2E Tests (3-4 hours)

### TASK-034: [TEST] Full Flow Integration
**Type**: `[TEST]`  
**Time**: 1.5 hours  
**Status**: ‚è≥

**Description**: Write integration test for complete flow.

**Files to Create**:
- `backend/tests/integration/test_full_flow.py`

**Test Cases**:
1. Good SEO site ‚Üí score > 7
2. Bad SEO site ‚Üí score < 5
3. Partial results (some checks fail)

**Acceptance Criteria**:
- ‚úÖ 3 tests written
- ‚úÖ Tests use test database
- ‚úÖ Tests run all 6 checks

**Dependencies**: TASK-025, TASK-033

---

### TASK-035: [TEST] E2E with Real Sites
**Type**: `[TEST]`  
**Time**: 1.5 hours  
**Status**: ‚è≥

**Description**: Write E2E tests with real sites.

**Files to Create**:
- `backend/tests/e2e/test_real_sites.py`

**Test Cases**:
1. updates.idalite.ru ‚Üí expect good score
2. Test site with known SEO issues ‚Üí expect low score

**Mark**: `@pytest.mark.e2e`

**Acceptance Criteria**:
- ‚úÖ 2 E2E tests written
- ‚úÖ Tests use real HTTP (no mocks)
- ‚úÖ Tests marked with @pytest.mark.e2e

**Dependencies**: TASK-034

---

### TASK-036: [REFACTOR] Code Coverage
**Type**: `[REFACTOR]`  
**Time**: 1 hour  
**Status**: ‚è≥

**Description**: Ensure 80%+ test coverage.

**Commands**:
```bash
cd backend/
pytest --cov=app --cov-report=html --cov-report=term-missing
open htmlcov/index.html
```

**Tasks**:
- Identify uncovered lines
- Add missing tests
- Refactor if needed

**Acceptance Criteria**:
- ‚úÖ Coverage > 80%
- ‚úÖ All critical paths covered

**Dependencies**: TASK-035

---

## Module 7: Deployment (2-3 hours)

### TASK-037: [CONFIG] Railway - Backend
**Type**: `[CONFIG]`  
**Time**: 1 hour  
**Status**: ‚è≥

**Description**: Deploy Backend API to Railway.

**Steps**:
1. Create Railway project
2. Add PostgreSQL database
3. Add Backend service
4. Configure env vars (DATABASE_URL)
5. Deploy

**Files to Create**:
- `backend/Dockerfile`
- `backend/.dockerignore`

**Acceptance Criteria**:
- ‚úÖ Backend deployed
- ‚úÖ Health endpoint accessible
- ‚úÖ Database connected

**Dependencies**: TASK-036

---

### TASK-038: [CONFIG] Railway - Bot
**Type**: `[CONFIG]`  
**Time**: 45 min  
**Status**: ‚è≥

**Description**: Deploy Telegram Bot to Railway.

**Steps**:
1. Add Bot service to Railway project
2. Configure env vars (BOT_TOKEN, API_URL)
3. Deploy

**Files to Create**:
- `telegram-bot/Dockerfile`

**Acceptance Criteria**:
- ‚úÖ Bot deployed
- ‚úÖ Bot responding to /start

**Dependencies**: TASK-037

---

### TASK-039: [TEST] Smoke Tests (Production)
**Type**: `[TEST]`  
**Time**: 30 min  
**Status**: ‚è≥

**Description**: Run smoke tests in production.

**Tests**:
1. Send test request via Telegram
2. Verify report received
3. Check database has records
4. Check logs in Railway

**Acceptance Criteria**:
- ‚úÖ At least 1 successful check in production
- ‚úÖ No errors in logs

**Dependencies**: TASK-038

---

### TASK-040: [CONFIG] Monitoring Setup
**Type**: `[CONFIG]`  
**Time**: 30 min  
**Status**: ‚è≥

**Description**: Setup basic monitoring.

**Tools**:
- Railway logs (built-in)
- Sentry (optional)

**Acceptance Criteria**:
- ‚úÖ Can view logs in Railway
- ‚úÖ Error tracking configured (optional)

**Dependencies**: TASK-039

---

## Module 8: Documentation & Polish (1-2 hours)

### TASK-041: [CONFIG] Update Documentation
**Type**: `[CONFIG]`  
**Time**: 45 min  
**Status**: ‚è≥

**Description**: Update project documentation.

**Files to Update**:
- `README.md` ‚Äî Installation, usage
- `backend/README.md` ‚Äî API docs
- `telegram-bot/README.md` ‚Äî Bot setup
- `.env.example` files

**Acceptance Criteria**:
- ‚úÖ Clear installation instructions
- ‚úÖ Environment variables documented
- ‚úÖ API endpoints documented

**Dependencies**: TASK-040

---

### TASK-042: [REFACTOR] Final Polish
**Type**: `[REFACTOR]`  
**Time**: 1 hour  
**Status**: ‚è≥

**Description**: Final code cleanup and improvements.

**Tasks**:
- Run linters (ruff, mypy)
- Fix any warnings
- Add missing docstrings
- Code review (self)

**Acceptance Criteria**:
- ‚úÖ No linter errors
- ‚úÖ All public functions have docstrings
- ‚úÖ Code follows conventions

**Dependencies**: TASK-041

---

## Summary

**Total Tasks**: 42  
**Total Time**: 25-32 hours  
**Timeline**: 10 days (2.5-3.5 hours/day)

### Task Distribution

| Module | Tasks | Time |
|--------|-------|------|
| 1. Setup | 4 tasks | 2-3h |
| 2. Checks | 12 tasks | 8-10h |
| 3. Report | 2 tasks | 2h |
| 4. API | 7 tasks | 4-5h |
| 5. Bot | 8 tasks | 4-5h |
| 6. Tests | 3 tasks | 3-4h |
| 7. Deploy | 4 tasks | 2-3h |
| 8. Docs | 2 tasks | 1-2h |

### Critical Path

```
TASK-001 ‚Üí TASK-002 ‚Üí TASK-003 ‚Üí TASK-004
    ‚Üì
TASK-005 ‚Üí TASK-006 (Robots)
    ‚Üì
TASK-007 ‚Üí TASK-008 (Sitemap)
    ‚Üì
TASK-009 ‚Üí TASK-010 (Analytics)
    ‚Üì
TASK-011 ‚Üí TASK-012 (Noindex)
    ‚Üì
TASK-013 ‚Üí TASK-014 (Meta)
    ‚Üì
TASK-015 ‚Üí TASK-016 (Headings)
    ‚Üì
TASK-017 ‚Üí TASK-018 (Report)
    ‚Üì
TASK-019 ‚Üí TASK-020 ‚Üí TASK-021 ‚Üí TASK-022 (API)
    ‚Üì
TASK-023 ‚Üí TASK-024 ‚Üí TASK-025
    ‚Üì
TASK-026 ‚Üí TASK-027 ‚Üí TASK-028 ‚Üí ... ‚Üí TASK-033 (Bot)
    ‚Üì
TASK-034 ‚Üí TASK-035 ‚Üí TASK-036 (Tests)
    ‚Üì
TASK-037 ‚Üí TASK-038 ‚Üí TASK-039 ‚Üí TASK-040 (Deploy)
    ‚Üì
TASK-041 ‚Üí TASK-042 (Polish)
```

---

## Next Steps

1. **Review this task list**
2. **Start with TASK-001**: Initialize project structure
3. **Follow TDD**: Always write tests before implementation
4. **Track progress**: Update status as tasks complete
5. **Daily target**: 3-4 tasks/day

---

## Task Tracking Template

Copy this to track progress:

```markdown
## Day 1 (Date: ____)
- [ ] TASK-001: Initialize project structure
- [ ] TASK-002: Setup dependencies
- [ ] TASK-003: Configure linters
- [ ] TASK-004: Setup database schema

## Day 2 (Date: ____)
- [ ] TASK-005: [TEST] Robots.txt
- [ ] TASK-006: [IMPL] Robots.txt
- [ ] TASK-007: [TEST] Sitemap.xml
- [ ] TASK-008: [IMPL] Sitemap.xml
```

---

**Status**: ‚úÖ Ready for Implementation  
**Next**: Begin TASK-001
